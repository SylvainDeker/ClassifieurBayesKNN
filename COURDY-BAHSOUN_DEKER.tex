%%%% patron de format latex pour rfia 2000.
%%%% sans garanties. Plaintes \`a envoyer \`a \dev\null.
%%%% deux colonnes pas de num\'erotation et 10 points
%%%% necessite les fichiers a4.sty french.sty et rfia2000.sty

% %%%% Pour \LaTeXe
\documentclass[a4paper,twoside,french]{article}
\usepackage{rfia2000}
\usepackage{inputenc}
\usepackage[T1]{fontenc}
\usepackage{babel}
\usepackage{times}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{graphicx}

%%%% Pour \LaTeXe sans babel
%%%% \documentclass[a4paper,twoside]{article}
%%%% \usepackage{rfia2000}
%%%% \usepackage{french}
%%%% \usepackage{times}

%%%% Pour \LaTeX remplacer les trois ligne pr\'ec\'edente par les deux
%%%% suivantes
%%%%\documentstyle[a4,french]{article}
%%%%\input{rfia2000}

% \begin{document}
%%%%%Pas de date
\date{}
%%%%% Titre gras 14 points
\title{\Large\bf Résultats de recherche sur la classification supervisée}
%%%%% Si auteur unique
%\author{L. Auteur \\
%%  Son institut \\
%%  Son addresse \\
%%  Son email}
%%%% pour deux auteurs
\author{\begin{tabular}[t]{c@{\extracolsep{8em}}c}
%%%% pour trois auteurs
%%%%\author{\begin{tabular}[t]{c@{\extracolsep{6em}}c@{\extracolsep{6em}}c}
%%%% pour quatre auteurs
%%%%\author{\begin{tabular}[t]{c@{\extracolsep{4em}}c@{\extracolsep{4em}}c@{\extracolsep{4em}}c}
%%%%pour plus d\'ebrouillez-vous !
M. Deker Sylvain${}^1$  & Mme. Courdy-Bahsoun Clémence${}^2$ \\
\end{tabular}
{} \\
 \\
${}^1$        M1 IGAI  Université Paul Sabatier    \\
${}^2$        M1 IGAI  Université Paul Sabatier
{} \\
 \\
sylvain.deker@univ-tlse3.fr\\
clemence.courdy-bahsoun@univ-tlse3.fr
}

\begin{document}

\maketitle

%%%%  Pas de num\'erotation sur la page de titre
\thispagestyle{empty}
\subsection*{Résumé}
{\em
Cet article vise à comparer les avantages et les désavantages des classifications supervisées par bayésienne avec gaussienne et par la méthode des k-plus proches voisins, en s'appuyant sur les résultats obtenus sur un même jeu de données.
}
\subsection*{Mots Clef}
Apprentissage, classification bayésienne, classification k-ppv.

\section{Introduction}

La classification bayésienne avec gaussienne et l'approche par la méthode des k-ppv sont des classifications supervisées dont l'objectif est de répartir les données par classe avec un taux d'erreur minimisé. Les tests sont menés sur un jeu de données contenant une centaine d'occurences de la prononciation d'une dizaine de voyelle aau format csv.\\
A l'aide des travaux réalisés précédamment et en adaptant un peu le code nous avons pu implémenter le modèle de Bayes. L'implémentation pour une approche par les k-ppv, le sujet nous imposait l'utilisation de \textit{Scikitlearn}.\\
Dans les tests menés les données fournies ont été repartie de telle sorte à avoir 80\% de données d'apprentissage et 20\% de données de tests. Dans les démarches d'apprentissage le choix d'un taux de données d'apprentissage élevé favorise l'obtention de meilleurs résultats, ici une meilleur prédiction de la répartition par classe.

\section{Classification bayésienne avec Gaussienne}
La classification bayéssienne avec Gaussienne est une minimisation de la vraisemblance qui vise à prédire la classe d'appartenance la plus probable d'une donnée. Néanmoins avec des données réelles il est difficile d'obtenir des résultats satisfaisants car les données ne sont pas simples. Ainsi pour améliorer le modèle on tient compte de la probabilité a priori en applicant la loi de Bayes.\\
Dans les tps précedant, nous avions déjà implémenté en python l'algorithme de prédiction permettant de classer les données fournies. Ici nous somme reparti de ce code qui était basé sur une simplification de la vraisemblance en log-vraisemblance. C'est-à-dire que la vraisemblance qui est une expression exponentielle a été simplifié par l'application du logarithme népérien afin d'obtenir un calcul un peu plus optimisé. De plus toutes les constantes ne dépendant pas des données ont été supprimé, n'apportant pas une précision indispensable dans la reconnaissance des données.

\section{Classification k-NN}
La méthode des K plus proches voisins (K-NN) a pour but de classifier des points cibles (classe méconnue) en fonction de leurs distances par rapport à des points constituant un échantillon d\'apprentissage (c\'est-à-dire dont la classe est connue a priori). Le calcul de la distance peut dépendre de l'expérience menée, Scikitlearn se base sur un calcul euclidien de la distance entre les données de l'échantillon, placées dans un repère après un traitement par une \textbf{A}nalyse en \textbf{C}omposantes \textbf{P}rincipales, et les centroïdes de la base d'apprentissage.
Scikit learn est une bibliothèque libre pour python dont certaines fonctionnalités ont été utilisé pour implémenter la classification par k-NN. En effet toutes les fonctions appelé sur la variable n de la fonction k\_NN sont des fonctions appelés pour la classe KNeighborsClassifier, une classe de la bibliothèque permettant d'effectuer les traitements nécéssaire à une classification par plus proche voisin.

\paragraph{}
\begin{algorithm}
 \caption{k\_NN}
 \begin{algorithmic}
  \REQUIRE  train\_data, train\_labels, test\_data, test\_labels
  \ENSURE  m : matrice de confusion \\ p : precision
  \STATE  n = neighbors.KNeighborsClassifier(n\_neighbours,weights = 'distance')
  \STATE n.fit(train\_data,train\_labels) \%apprentissage
  \STATE y = n.predict(test\_data)
  mconf = matriceConf(test\_labels,y) \%calcul matrice de confusion, fonction rédigé
  \RETURN (mconf[0], mconf[1])
 \end{algorithmic}

\end{algorithm}


\section{Evaluation par validation croisée}
La validation croisée est une méthode d\'estimation de la fiabilité d\'un modèle
fondé sur la technique d'échantillonage. Les essembles de données d'apprentissages
sont les fichiers de test data2.csv, data3.csv et data12.csv sur lequel on peut
entrainer le modèle. Nous appelons "leanring ratio" la proportion des données
d'un fichier dédié à l\'apprentissage, la partie restante sert d\'échantillons
da validation. Cette méthode de test s'appelle "testset validation" ou "holdout method".

\section{Résultats}

Nous rappelons que le "leanring ratio" est la proportion des données
d'un fichier dédié à l\'apprentissage, la partie restante servant d\'échantillons
da validation. Pour evaluer la performance d'un algorithme, nous disposons de deux métriques,le premier étant le temps nécéssaire au processus d'apprentissage et de validation, et la second est la précision avec laquelle les résultats sont fiables.
Une série de 50 tests ont été effectués sur les fichiers test data2.csv, data3.csv et data12.csv pour chaque learning ratio suivant : 0.2 , 0.4, 0.6 et 0.8.
Les résultats ci-dessous présentes les moyennes sur ces 50 tests.
\subsection{Matrice de confusion}
Afin d'analyser et de pouvoir comparer les résultats obtenus par les deux méthodes étudiées ici, on calcule pour chaque échantillon la matrice de confusion, permettant de déduire un taux d'erreur. Cette matrice est construite à l'aide d'une classe présentes dans la bibiliothèque Scikitlearn et en appliquant les calculs nécessaire pour calculer le taux d'erreur.
\subsection{Jeu de test}
\subsubsection{jeux de test data2.csv}
\paragraph{}
 \includegraphics[width=7.5cm,scale=0.5]{images/data2.png}
 \paragraph{}
 \subsubsection{jeux de test data3.csv}
 \includegraphics[width=7.5cm,scale=0.5]{images/data3_1.png}
  \paragraph{}
 \includegraphics[width=7.5cm,scale=0.5]{images/data3_2.png}
  \paragraph{}
 \includegraphics[width=7.5cm,scale=0.5]{images/data3_3.png}
 \subsubsection{jeux de test data12.csv}
 
\subsection{Observations}
\subsubsection{Learning ratio = 0.2}
 20 % des données ont été utilisé pour l'apprentissage de facons aléatoire pour chaque jeu de test (fichier.csv).
 Les données pour chaque jeu de test est une moyenne de 50 tests réalisés dans le mêmes conditions.
 Dans ce context nous observons que l'algorithme KNN est environ 40 fois plus rapide de celui de Bayes.
 La précision reste stable, KNN est très légerement moins précis que Bayes pour les deux premiers jeux de test.
 \paragraph{}
 \includegraphics[width=7.5cm,scale=0.5]{images/ratio02.png}

 \subsubsection{Learning ratio = 0.4}
 40 % des données ont été utilisé pour l'apprentissage de facons aléatoire pour chaque jeu de test (fichier.csv).
 Les données pour chaque jeu de test est une moyenne de 50 tests réalisés dans le mêmes conditions.
 Dans ce context nous observons que l'algorithme KNN est environ 60 fois plus rapide de celui de Bayes.
 La précision reste stable, KNN est très légerement plus précis que Bayes pour les deux derniers jeux de test.

 \paragraph{}
 \includegraphics[width=7.5cm,scale=0.5]{images/ratio04.png}

 \subsubsection{Learning ratio = 0.6}
 60 % des données ont été utilisé pour l'apprentissage de facons aléatoire pour chaque jeu de test (fichier.csv).
 Les données pour chaque jeu de test est une moyenne de 50 tests réalisés dans le mêmes conditions.
 Dans ce context nous observons que l'algorithme KNN est environ 80 fois plus rapide de celui de Bayes.
 La précision reste stable, KNN est très légerement plus précis que Bayes pour les deux derniers jeux de test.


 \paragraph{}
 \includegraphics[width=7.5cm,scale=0.5]{images/ratio06.png}

 \subsubsection{Learning ratio = 0.8}
 80 % des données ont été utilisé pour l'apprentissage de facons aléatoire pour chaque jeu de test (fichier.csv).
 Les données pour chaque jeu de test est une moyenne de 50 tests réalisés dans le mêmes conditions.
 Dans ce context nous observons que l'algorithme KNN est environ 110 fois plus rapide de celui de Bayes.
 La précision reste stable, KNN est très légerement plus précis que Bayes pour les deux derniers jeux de test.
 \paragraph{}
 \includegraphics[width=7.5cm,scale=0.5]{images/ratio08.png}

 \subsection{Analyse temporelle}
 \subsubsection{Bayes}
 \paragraph{}
 \includegraphics[width=7.5cm,scale=0.5]{images/durationBayes.png}\\

 \subsubsection{K\_NN}
 \paragraph{}
 \includegraphics[width=7.5cm,scale=0.5]{images/durationKNN.png}

  \subsection{Analyse précision}
 \subsubsection{Bayes}
 \paragraph{}
 \includegraphics[width=7.5cm,scale=0.5]{images/precisionBayes.png}\\

 \subsubsection{K\_NN}
 \paragraph{}
 \includegraphics[width=7.5cm,scale=0.5]{images/precisionKNN.png}

\section{Conclusion}


\end{document}
